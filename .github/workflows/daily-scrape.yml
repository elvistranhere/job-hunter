# Daily Job Scrape — runs in YOUR private fork, not on the public repo.
#
# Setup (one-time):
#   1. Fork this repo to your GitHub account
#   2. Go to Settings → Secrets and variables → Actions
#   3. Add these secrets:
#      - GMAIL_USER         → Your Gmail address
#      - GMAIL_APP_PASSWORD → Gmail App Password (https://myaccount.google.com/apppasswords)
#      - EMAIL_TO           → Comma-separated recipient emails
#   4. Go to Actions → "Daily Job Scrape" → Enable workflow
#   5. Click "Run workflow" for your first manual run
#   6. To enable daily automation, uncomment the schedule block below
#
# Customize:
#   - Change the cron time to match your timezone
#   - Add --no-senior to filter out senior roles
#   - Adjust --hours, --results, --min-score to your preference

name: Daily Job Scrape

on:
  schedule:
    - cron: '0 21 * * *'  # 9pm UTC = ~7am AEST / ~7:30am ACST
  workflow_dispatch:
    inputs:
      full_run:
        description: 'Run full 3-city x 7-role search matrix'
        required: false
        default: 'false'
        type: boolean
      min_score:
        description: 'Minimum score threshold for email'
        required: false
        default: '20'
        type: string

jobs:
  scrape-and-email:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Set up Python
        run: uv python install 3.12

      - name: Install dependencies
        run: uv sync

      - name: Install Xvfb
        run: sudo apt-get update && sudo apt-get install -y xvfb

      - name: Run scraper (focused daily)
        if: ${{ github.event.inputs.full_run != 'true' }}
        run: |
          xvfb-run --auto-servernum --server-args="-screen 0 1280x720x24" \
            uv run python scrape.py \
              --hours 24 \
              --results 20 \
              --no-senior
        env:
          PYTHONUNBUFFERED: "1"
          CHROME_BINARY: /usr/bin/google-chrome-stable

      - name: Run scraper (full matrix)
        if: ${{ github.event.inputs.full_run == 'true' }}
        run: |
          xvfb-run --auto-servernum --server-args="-screen 0 1280x720x24" \
            uv run python scrape.py --hours 48
        env:
          PYTHONUNBUFFERED: "1"
          CHROME_BINARY: /usr/bin/google-chrome-stable

      - name: Send email digest
        run: |
          uv run python email_digest.py \
            --min-score ${{ github.event.inputs.min_score || '20' }}
        env:
          GMAIL_USER: ${{ secrets.GMAIL_USER }}
          GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: job-results-${{ github.run_number }}
          path: jobs/
          retention-days: 7
